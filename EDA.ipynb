{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5109337f-b068-4136-8748-872b2fc6a67d",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc70e10-d667-4f8f-b0b5-1a48da080efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc # Garbage Collector to help manage memory\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad00ffd1-3107-4eb0-bb92-e7cdd762a50a",
   "metadata": {},
   "source": [
    "Optimasi Memori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62032fa0-5b36-4c2d-9e7e-42255954e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" Iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else: # float types\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3ab7a-b0d7-4dee-9555-a5c0c331d7d4",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902ba96-d6ae-4828-8e72-972501da08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df, df_name, id_cols=[], target_col=None):\n",
    "    \"\"\"\n",
    "    Performs a standard EDA process on a given dataframe.\n",
    "    Includes: Info, Head, Missing Values, Descriptive Stats, Univariate Plots, Outlier Plots.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting EDA for {df_name} ---\")\n",
    "\n",
    "    # Apply memory reduction\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    print(\"\\n--- Basic Information ---\")\n",
    "    print(df.info())\n",
    "    print(\"\\n--- First 5 Rows ---\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\n--- Missing Values (Percentage) ---\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentage = (missing_values[missing_values > 0] / len(df)) * 100\n",
    "    if not missing_percentage.empty:\n",
    "        print(missing_percentage.sort_values(ascending=False))\n",
    "    else:\n",
    "        print(\"No missing values found.\")\n",
    "\n",
    "    # --- Descriptive Statistics ---\n",
    "    print(\"\\n--- Descriptive Statistics for Numerical Features ---\")\n",
    "    print(df.select_dtypes(include=np.number).describe().transpose()) # Transpose for better readability\n",
    "\n",
    "    # Check if there are any categorical columns before describing them\n",
    "    categorical_cols_for_desc = df.select_dtypes(include='category')\n",
    "    print(\"\\n--- Descriptive Statistics for Categorical Features ---\")\n",
    "    if not categorical_cols_for_desc.empty:\n",
    "        print(categorical_cols_for_desc.describe().transpose())\n",
    "    else:\n",
    "        print(\"No categorical columns found for descriptive statistics.\")\n",
    "\n",
    "\n",
    "    # --- Univariate Analysis: Numerical Features Distribution ---\n",
    "    print(\"\\n--- Univariate Analysis: Numerical Features Distribution ---\")\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns.drop(id_cols, errors='ignore')\n",
    "    if target_col and target_col in numerical_cols:\n",
    "        numerical_cols = numerical_cols.drop(target_col, errors='ignore')\n",
    "\n",
    "    # Plot histograms for a sample of numerical columns to avoid too many plots\n",
    "    n_cols_to_plot = min(len(numerical_cols), 5) # Plot up to 5 random numerical columns\n",
    "    selected_numerical_cols = np.array([]) \n",
    "    if n_cols_to_plot > 0:\n",
    "        selected_numerical_cols = np.random.choice(numerical_cols, n_cols_to_plot, replace=False)\n",
    "        for col in selected_numerical_cols:\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            sns.histplot(df[col].dropna(), kde=True, bins=50)\n",
    "            plt.title(f'Distribution of {col} in {df_name}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No numerical columns to plot (excluding IDs and target).\")\n",
    "\n",
    "    # --- Univariate Analysis: Categorical Features Distribution ---\n",
    "    print(\"\\n--- Univariate Analysis: Categorical Features Distribution ---\")\n",
    "    categorical_cols = df.select_dtypes(include='category').columns\n",
    "\n",
    "    if not categorical_cols.empty:\n",
    "        for col in categorical_cols:\n",
    "            if df[col].nunique() < 50: \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.countplot(y=col, data=df, order=df[col].value_counts().index)\n",
    "                plt.title(f'Distribution of {col} in {df_name}')\n",
    "                plt.xlabel('Count')\n",
    "                plt.ylabel(col)\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Skipping countplot for {col} in {df_name} due to high number of unique categories ({df[col].nunique()}).\")\n",
    "    else:\n",
    "        print(\"No categorical columns found for univariate analysis.\")\n",
    "\n",
    "    # --- Outlier Detection (using Box Plots for key numerical features) ---\n",
    "    print(\"\\n--- Outlier Detection (using Box Plots) ---\")\n",
    "    outlier_cols_sample = selected_numerical_cols \n",
    "\n",
    "    # Change .empty to len() == 0 for NumPy array check\n",
    "    if len(outlier_cols_sample) > 0: \n",
    "        for col in outlier_cols_sample:\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            sns.boxplot(x=df[col].dropna())\n",
    "            plt.title(f'Box Plot of {col} for Outlier Detection in {df_name}')\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No numerical columns selected for outlier detection plots.\")\n",
    "\n",
    "\n",
    "    # --- Bivariate Analysis (if a target column is specified) ---\n",
    "    if target_col and target_col in df.columns:\n",
    "        print(f\"\\n--- Bivariate Analysis: Relationship with {target_col} ---\")\n",
    "        # Numerical Features vs. TARGET\n",
    "        # Change .empty to len() == 0 for NumPy array check\n",
    "        if len(selected_numerical_cols) > 0:\n",
    "            for col in selected_numerical_cols:\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.boxplot(x=target_col, y=col, data=df)\n",
    "                plt.title(f'{col} vs. {target_col} in {df_name}')\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\"No numerical columns to plot against target.\")\n",
    "\n",
    "        # Categorical Features vs. TARGET\n",
    "        if not categorical_cols.empty:\n",
    "            for col in categorical_cols:\n",
    "                if df[col].nunique() < 20: # Limit to categories with fewer unique values\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    sns.barplot(x=col, y=target_col, data=df, ci=None)\n",
    "                    plt.title(f'{target_col} Rate by {col} in {df_name}')\n",
    "                    plt.ylabel(f'{target_col} Rate (TARGET = 1)')\n",
    "                    plt.xticks(rotation=45, ha='right')\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(f\"Skipping bar plot for {col} vs {target_col} in {df_name} due to high number of unique categories.\")\n",
    "        else:\n",
    "            print(\"No categorical columns to plot against target.\")\n",
    "\n",
    "    # --- Correlation Heatmap (for key numerical features) ---\n",
    "    print(f\"\\n--- Correlation Heatmap for {df_name} (Sample of Numerical Features) ---\")\n",
    "    # Limit features for correlation to avoid very large heatmaps\n",
    "    corr_df = df.select_dtypes(include=np.number)\n",
    "    # Reduce columns if too many (e.g., take top correlated with target if exists, or a random sample)\n",
    "    if corr_df.shape[1] > 15:\n",
    "        # If target_col exists, pick top correlated. Otherwise, random random.choice(corr_df.columns, 15, replace=False)\n",
    "        if target_col and target_col in corr_df.columns:\n",
    "            top_corr_cols = corr_df.corrwith(corr_df[target_col]).abs().sort_values(ascending=False).index[:15]\n",
    "            corr_df = corr_df[top_corr_cols]\n",
    "        else:\n",
    "            corr_df = corr_df[np.random.choice(corr_df.columns, 15, replace=False)]\n",
    "\n",
    "    if corr_df.shape[1] > 1: # Ensure there's more than one column for correlation\n",
    "        correlation_matrix = corr_df.corr()\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "        plt.title(f'Correlation Matrix of Key Numerical Features in {df_name}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough numerical columns to plot a correlation heatmap.\")\n",
    "\n",
    "    print(f\"--- Finished EDA for {df_name} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9d9dd-f67a-4aa8-9fe1-a85d23bbb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'application_train.csv'\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path}' not found. Please check the file path.\")\n",
    "    exit()\n",
    "\n",
    "target_counts = df_train['TARGET'].value_counts()\n",
    "target_percentage = df_train['TARGET'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Jumlah data per kelas TARGET:\")\n",
    "print(target_counts)\n",
    "print(\"\\nPersentase data per kelas TARGET:\")\n",
    "print(target_percentage)\n",
    "\n",
    "# Membuat visualisasi\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values, palette='viridis')\n",
    "\n",
    "# Menambahkan label dan judul\n",
    "plt.title('Distribusi Kelas Target (TARGET)', fontsize=16)\n",
    "plt.xlabel('Kelas Target (0: Tidak Gagal Bayar, 1: Gagal Bayar)', fontsize=12)\n",
    "plt.ylabel('Jumlah Aplikasi', fontsize=12)\n",
    "plt.xticks(ticks=[0, 1], labels=['0 (Tidak Gagal Bayar)', '1 (Gagal Bayar)'])\n",
    "\n",
    "# Menambahkan teks persentase di atas setiap bar\n",
    "for index, value in enumerate(target_counts.values):\n",
    "    plt.text(index, value + 1000, f'{target_percentage.iloc[index]:.2f}%',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualisasi dalam bentuk pie chart (opsional, untuk melihat proporsi)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(target_counts, labels=['0 (Tidak Gagal Bayar)', '1 (Gagal Bayar)'],\n",
    "        autopct='%1.1f%%', startangle=90, colors=['steelblue','seagreen'], explode=(0, 0.1))\n",
    "plt.title('Proporsi Kelas Target (TARGET)', fontsize=16)\n",
    "plt.axis('equal') # Memastikan pie chart berbentuk lingkaran\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a4789-0b3c-4d40-b5d5-413435a8aabd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- EDA for application_train.csv ---\")\n",
    "try:\n",
    "    app_train = pd.read_csv('application_train.csv')\n",
    "    perform_eda(app_train, 'application_train.csv', id_cols=['SK_ID_CURR'], target_col='TARGET')\n",
    "    del app_train \n",
    "    gc.collect() \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: application_train.csv not found. Please ensure the file is in the correct directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3606ef2-75a1-47c5-97aa-5aa4001893dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA for application_test.csv ---\")\n",
    "try:\n",
    "    app_test = pd.read_csv('application_test.csv')\n",
    "    perform_eda(app_test, 'application_test.csv', id_cols=['SK_ID_CURR']) # No target column\n",
    "    del app_test\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: application_test.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b24d9-c7bb-4f72-a0a2-1d4318873bae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA for bureau.csv ---\")\n",
    "try:\n",
    "    bureau = pd.read_csv('bureau.csv')\n",
    "    perform_eda(bureau, 'bureau.csv', id_cols=['SK_ID_CURR', 'SK_ID_BUREAU'])\n",
    "    del bureau\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: bureau.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa90815-b26d-464a-89d0-978a0ff33cd5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA for bureau_balance.csv ---\")\n",
    "try:\n",
    "    bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "    perform_eda(bureau_balance, 'bureau_balance.csv', id_cols=['SK_ID_BUREAU'])\n",
    "    del bureau_balance\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: bureau_balance.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b36f1-3975-4a93-885c-4622efb07f8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA for POS_CASH_balance.csv ---\")\n",
    "try:\n",
    "    pos_cash_balance = pd.read_csv('POS_CASH_balance.csv')\n",
    "    perform_eda(pos_cash_balance, 'POS_CASH_balance.csv', id_cols=['SK_ID_CURR', 'SK_ID_PREV'])\n",
    "    del pos_cash_balance\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: POS_CASH_balance.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169dbbf-ea1c-452a-a841-73277d5f7ab6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA for credit_card_balance.csv ---\")\n",
    "try:\n",
    "    credit_card_balance = pd.read_csv('credit_card_balance.csv')\n",
    "    perform_eda(credit_card_balance, 'credit_card_balance.csv', id_cols=['SK_ID_CURR', 'SK_ID_PREV'])\n",
    "    del credit_card_balance\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: credit_card_balance.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89cc8f8-c1ca-4174-bc62-99102632e0d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA for previous_application.csv ---\")\n",
    "try:\n",
    "    previous_application = pd.read_csv('previous_application.csv')\n",
    "    perform_eda(previous_application, 'previous_application.csv', id_cols=['SK_ID_CURR', 'SK_ID_PREV'])\n",
    "    del previous_application\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: previous_application.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ff46f-a59d-4faa-9be5-ebd14b61c147",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA for installments_payments.csv ---\")\n",
    "try:\n",
    "    installments_payments = pd.read_csv('installments_payments.csv')\n",
    "    perform_eda(installments_payments, 'installments_payments.csv', id_cols=['SK_ID_CURR', 'SK_ID_PREV'])\n",
    "    del installments_payments\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: installments_payments.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d7c23-7de1-4a3d-b742-8e9042ad7f13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- HomeCredit_columns_description.csv ---\")\n",
    "try:\n",
    "    column_descriptions = pd.read_csv('HomeCredit_columns_description.csv', encoding='latin1') \n",
    "    print(\"HomeCredit_columns_description.csv loaded successfully!\")\n",
    "    print(\"\\n--- Sample Column Descriptions ---\")\n",
    "    print(column_descriptions.head())\n",
    "    del column_descriptions\n",
    "    gc.collect()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: HomeCredit_columns_description.csv not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
